{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment to train two agents to play Tennis.  This is the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the [Getting Started](./README.md) section of the project README.md."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.8 64bit [GCC 5.4.0 20160609]"
        },
        {
         "module": "IPython",
         "version": "7.2.0"
        },
        {
         "module": "OS",
         "version": "Linux 4.4.0 141 generic x86_64 with Ubuntu 16.04 xenial"
        },
        {
         "module": "numpy",
         "version": "1.15.4"
        },
        {
         "module": "pandas",
         "version": "0.23.4"
        },
        {
         "module": "matplotlib",
         "version": "3.0.2"
        },
        {
         "module": "torch",
         "version": "0.4.0"
        },
        {
         "module": "unityagents",
         "version": "0.4.0"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.8 64bit [GCC 5.4.0 20160609]</td></tr><tr><td>IPython</td><td>7.2.0</td></tr><tr><td>OS</td><td>Linux 4.4.0 141 generic x86_64 with Ubuntu 16.04 xenial</td></tr><tr><td>numpy</td><td>1.15.4</td></tr><tr><td>pandas</td><td>0.23.4</td></tr><tr><td>matplotlib</td><td>3.0.2</td></tr><tr><td>torch</td><td>0.4.0</td></tr><tr><td>unityagents</td><td>0.4.0</td></tr><tr><td colspan='2'>Fri Feb 01 20:26:38 2019 CST</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.6.8 64bit [GCC 5.4.0 20160609] \\\\ \\hline\n",
       "IPython & 7.2.0 \\\\ \\hline\n",
       "OS & Linux 4.4.0 141 generic x86\\_64 with Ubuntu 16.04 xenial \\\\ \\hline\n",
       "numpy & 1.15.4 \\\\ \\hline\n",
       "pandas & 0.23.4 \\\\ \\hline\n",
       "matplotlib & 3.0.2 \\\\ \\hline\n",
       "torch & 0.4.0 \\\\ \\hline\n",
       "unityagents & 0.4.0 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Fri Feb 01 20:26:38 2019 CST} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.6.8 64bit [GCC 5.4.0 20160609]\n",
       "IPython 7.2.0\n",
       "OS Linux 4.4.0 141 generic x86_64 with Ubuntu 16.04 xenial\n",
       "numpy 1.15.4\n",
       "pandas 0.23.4\n",
       "matplotlib 3.0.2\n",
       "torch 0.4.0\n",
       "unityagents 0.4.0\n",
       "Fri Feb 01 20:26:38 2019 CST"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, pandas, matplotlib, torch, unityagents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import namedtuple, deque\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tennis_maddpg import UnityTennisEnv, Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using Linux on amd64 arch, then downloaded `Tennis.x86_64`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```python\n",
    "env = UnityTennisEnv(file_name=\"./Tennis_Linux/Tennis.x86_64\")\n",
    "```\n",
    "For headless operation add the no_graphics kwarg:\n",
    "```python\n",
    "env = UnityTennisEnv(file_name=\"./Tennis_Linux/Tennis.x86_64\", no_graphics=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_name 1549073275\n"
     ]
    }
   ],
   "source": [
    "env = UnityTennisEnv(file_name=\"./Tennis_Linux/Tennis.x86_64\", no_graphics=True)\n",
    "print('session_name', env.session_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set Hyperparameters\n",
    "\n",
    "Use the cell below to adjust the hyperparameters for training.  The current set of hyperparameters work well for training multi-agent deep reinforcement learning using both Action Space Noise (i.e. OUNoise) as well as Parameter Space Noise with Layer Normalization.\n",
    "\n",
    "The main factors that contributed to successfull learning of the Tennis agents were:\n",
    "1. Preload the Replay Buffer with 10000 random (s, a, r, s') transitions before any training.\n",
    "2. Train and update the nets with one batch every time a new transition is added (after preloading).\n",
    "3. Use a heafty batch size (i.e. 256) when training.\n",
    "4. Bump up the learning rates for both the actor and critic a bit more than the standard.  Same with Tau.\n",
    "5. Faster to train on the CPU.  (Because I only train on single batch per episode step.)\n",
    "6. Share Replay Buffer between Agents.  This is especially true if Prioritized Experience Replay is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRELOAD_STEPS = int(1e4)  # initialize the replay buffer with this many transitions.\n",
    "BUFFER_SIZE = int(2e5)    # replay buffer size\n",
    "BATCH_SIZE = 256          # minibatch size\n",
    "GAMMA = 0.99              # discount factor\n",
    "TAU = 0.02                # for soft update of target parameters\n",
    "LR_ACTOR = 2e-4           # Learning rate of the actor\n",
    "LR_CRITIC = 2e-3          # Learning rate of the critic\n",
    "UPDATE_EVERY = 1          # Update the network after this many steps.\n",
    "LEARN_EVERY = 1           # Train local network ever n-steps\n",
    "RANDOM_SEED = 0\n",
    "NUM_EPISODES = 4000\n",
    "\n",
    "USE_ASN = True  # Use Action Space Noise\n",
    "ASN_KWARGS = {\n",
    "    'mu': 0.0,\n",
    "    'theta': 0.15,\n",
    "    'sigma': 0.20,\n",
    "    'scale_start': 1.0,\n",
    "    'scale_end': 0.01,\n",
    "    'decay': 0.99995\n",
    "}\n",
    "\n",
    "USE_PSN = True  # Use Parameter Space Noise\n",
    "PSN_KWARGS = {\n",
    "    'initial_stddev': 0.1,\n",
    "    'desired_action_stddev': 0.1,\n",
    "    'adoption_coefficient': 1.01\n",
    "}\n",
    "\n",
    "USE_PER = False  # Use Prioritized Experience Replay\n",
    "PER_PRIORITY_START = 1.0\n",
    "PER_PRIORITY_END = 0.3\n",
    "PER_PRIORITY_DECAY = 0.9999\n",
    "\n",
    "AGENT_SHARE_MEMORY = True\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Agents!\n",
    "\n",
    "Set up training subroutine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, agent1, agent2, preload_steps=PRELOAD_STEPS, n_episodes=NUM_EPISODES, print_interval=100):\n",
    "    \"\"\"Train using Deep Deterministic Policy Gradients.\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        t_max (int): maximum number of timesteps per episode\n",
    "        print_every (int): print after this many episodes. Also used to define length of the deque buffer.\n",
    "    \"\"\"\n",
    "    pri = PER_PRIORITY_START\n",
    "    scores = []  # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    scores_average = []\n",
    "    best = 0\n",
    "    early_stop = 0.5\n",
    "    # log_path = os.getcwd() + \"/log\"\n",
    "    model_dir = os.getcwd() + \"/model_dir/tennis\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    print('BUFFER_SIZE:', BUFFER_SIZE)\n",
    "\n",
    "    # fill replay buffer with rnd actions\n",
    "    obs = env.reset()\n",
    "    for _ in range(preload_steps):\n",
    "        actions = np.random.randn(2, 2)  # select an action (for each agent)\n",
    "\n",
    "        obs_next, rewards, dones = env.step(actions)\n",
    "\n",
    "        obs_critic = np.reshape(obs, (-1))\n",
    "        obs1 = np.concatenate((obs[0], obs_critic))\n",
    "        obs2 = np.concatenate((obs[1], obs_critic))\n",
    "\n",
    "        obs_critic_next = np.reshape(obs_next, (-1))\n",
    "        obs_next1 = np.concatenate((obs_next[0], obs_critic_next))\n",
    "        obs_next2 = np.concatenate((obs_next[1], obs_critic_next))\n",
    "\n",
    "        transition1 = (obs1, actions[0], rewards[0], obs_next1, dones[0])\n",
    "        transition2 = (obs2, actions[1], rewards[1], obs_next2, dones[1])\n",
    "\n",
    "        agent1.buffer.push(transition1)\n",
    "        agent2.buffer.push(transition2)\n",
    "\n",
    "        obs = obs_next\n",
    "        if dones.any():\n",
    "            obs = env.reset()\n",
    "\n",
    "    for i_episode in range(1, n_episodes + 1):\n",
    "        episode_rewards = np.zeros((env.num_agents, 1))  # initialize the score (for each agent)\n",
    "        obs = env.reset()  # reset the environment\n",
    "        agent1.reset()\n",
    "        agent2.reset()\n",
    "        t_step = 0\n",
    "        pri = max(pri * PER_PRIORITY_DECAY, PER_PRIORITY_END)\n",
    "\n",
    "        while True:\n",
    "\n",
    "            actions1 = agent1.act(obs[0])[0]\n",
    "            actions2 = agent2.act(obs[1])[0]\n",
    "\n",
    "            obs_next, rewards, dones = env.step([actions1, actions2])\n",
    "\n",
    "            obs_critic = np.reshape(obs, (-1))\n",
    "            obs1 = np.concatenate((obs[0], obs_critic))\n",
    "            obs2 = np.concatenate((obs[1], obs_critic))\n",
    "\n",
    "            obs_critic_next = np.reshape(obs_next, (-1))\n",
    "            obs_next1 = np.concatenate((obs_next[0], obs_critic_next))\n",
    "            obs_next2 = np.concatenate((obs_next[1], obs_critic_next))\n",
    "\n",
    "            agent1.step((obs1, actions1, rewards[0], obs_next1, dones[0]), pri)\n",
    "            agent2.step((obs2, actions2, rewards[1], obs_next2, dones[1]), pri)\n",
    "\n",
    "            episode_rewards += rewards  # update the score (for each agent)\n",
    "            obs = obs_next  # roll over states to next time step\n",
    "            if np.any(dones):  # exit loop if episode finished\n",
    "                break\n",
    "\n",
    "            t_step += 1  # increment the number of steps seen this episode.\n",
    "\n",
    "        episode_reward = np.max(episode_rewards)\n",
    "        scores_window.append(episode_reward)  # save most recent score\n",
    "        scores.append(episode_reward)\n",
    "        mean = np.mean(scores_window)\n",
    "        scores_average.append(mean)\n",
    "\n",
    "        agent1.postprocess(t_step, 0)\n",
    "        agent2.postprocess(t_step, 1)\n",
    "\n",
    "        summary = f'\\rEpisode {i_episode:>4}  Buffer Size: {len(agent1.buffer):>6}  Noise: {agent1.action_noise.scale:.2f}  t_step: {t_step:4}  Score (Avg): {episode_reward:.2f} ({mean:.3f})'\n",
    "\n",
    "        if mean >= early_stop and mean > best:\n",
    "            summary += \" (saved)\"\n",
    "            best = mean\n",
    "\n",
    "            fmt = 'maddpg_{}-EP_{}-winning_agent{}-score_{:.3f}.pt'\n",
    "            filename = os.path.join(model_dir, fmt.format(env.session_name, i_episode, episode_rewards.argmax(), best))\n",
    "            save_dict_list = [agent1.get_save_dict(), agent2.get_save_dict()]\n",
    "\n",
    "            torch.save(save_dict_list, filename)\n",
    "            copyfile(filename, os.path.join(model_dir, f'maddpg_{env.session_name}-best.pt'))\n",
    "            copyfile(filename, os.path.join(model_dir, f'maddpg_last-best.pt'))\n",
    "\n",
    "        if i_episode % print_interval == 0:\n",
    "            print(summary)\n",
    "        else:\n",
    "            print(summary, end=\"\")\n",
    "\n",
    "        if best > early_stop:\n",
    "            print(f'\\nEnvironment solved in {i_episode:d} episodes!\\tAverage Score: {mean:.3f}')\n",
    "            break\n",
    "\n",
    "    return scores, scores_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_config = {\n",
    "    'buffer_size': BUFFER_SIZE,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learn_every': LEARN_EVERY,\n",
    "    'update_every': UPDATE_EVERY,\n",
    "    'gamma': GAMMA,\n",
    "    'tau': TAU,\n",
    "    'lr_actor': LR_ACTOR,\n",
    "    'lr_critic': LR_CRITIC,\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'use_asn': USE_ASN,\n",
    "    'asn_kwargs': ASN_KWARGS,\n",
    "    'use_psn': USE_PSN,\n",
    "    'psn_kwargs': PSN_KWARGS,\n",
    "    'use_per': USE_PER\n",
    "}\n",
    "Agent.share_memory = AGENT_SHARE_MEMORY\n",
    "agent1 = Agent(env.state_size, env.action_size, 0, **agent_config)\n",
    "agent2 = Agent(env.state_size, env.action_size, 1, **agent_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUFFER_SIZE: 200000\n",
      "Episode  100  Buffer Size:  11515  Noise: 0.93  t_step:   14  Score (Avg): 0.00 (0.004)\n",
      "Episode  200  Buffer Size:  13777  Noise: 0.83  t_step:   30  Score (Avg): 0.09 (0.044)\n",
      "Episode  300  Buffer Size:  17236  Noise: 0.70  t_step:   55  Score (Avg): 0.10 (0.088)\n",
      "Episode  400  Buffer Size:  23865  Noise: 0.50  t_step:  164  Score (Avg): 0.40 (0.166)\n",
      "Episode  469  Buffer Size:  41210  Noise: 0.21  t_step: 1000  Score (Avg): 2.70 (0.517) (saved)\n",
      "Environment solved in 469 episodes!\tAverage Score: 0.517\n",
      "980.6394505500793 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "scores, scores_average = train(env, agent1, agent2)\n",
    "run_time = time.time() - t0\n",
    "print(run_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XecXHW5+PHPMzPbsiWbLekNUgiJ9NCkSlE6SpGiiKCCKHZ/XkBFsV3lXvWqSFNRihQVBKT3EloKJCEJpJBCerZk++7Mzszz++OcmZ26M5vs7Gx2n/frNa+dOefMOd85M3ue8+2iqhhjjDEAnnwnwBhjzOBhQcEYY0yUBQVjjDFRFhSMMcZEWVAwxhgTZUHBGGNMlAWFQUBEJotIm4h4+2FffxORn/VHulLsW0TkryKyU0Tmu8uuEpHtbvqrc3HcfBCRl0Tki/lOx2AhIp8RkWfynQ6TexYUBpCIrBeRTvcCGnmMV9UPVbVMVUM5Pv7nRSQUc+y1InJVH3ZxNHAyMFFVDxORAuA3wMfd9Df0QxoH/GIsIj8WkXtytO/rRURF5KSYZZ8WkddFpENEXkrYfqaIPCIidSLSKCJPi8g+Mes/4i6rF5GkTkYiUiUi/xaRdhHZICIXZ5nO5TG/i5CIdMW8vk5V/66qH9+NU7HLROSjIjJfRFpFZKmIHJ2w/msisk5EWkRkYex690bmVyLS4D5+JSLSy7FqReReEWl2b37+nsvPNhhZUBh4Z7oX0MhjywAf/43IsYFzgRtF5KAs3zsFWK+q7e7rMUAxsHxXEtIfOaPBTESmAecDWxNWNQL/B/wyxdsqgUeBfXDO73zgkZj13cA/gC+kOewfgYD73s8At4jInExpVdU5Mb+LV4GrY36jv8j0/lwRkSrgP8D/4JybG4H/iMgod/3hOOfxPGAk8Bfg3zG/rSuATwIHAPsDZwJX9nLIh4BtwGRgNPC//fyRBj9VtccAPYD1wEkplk8FFPC5r18Cfgq8BrQCzwA1Mdv/E+eH2wy8AsyJWfc34Gdpjv95YF7CsvnAxe7z44FNqdKMcxHqAkJAG3Af0O6muw14wd1+FvAszoVvJfDphLTdAjzhvjfVuXgJ+GKa9B8BvA40AUuA4xPe19s5+xywAWgAfhjzuU7BuYh2u59jSTb7y/L7fgo4rZfv/YvASxn2UeWe4+qE5dOdf9+4ZaXuZ5kZs+xu4Jd9THfSd5D423HT9BVgtXt+fgpMc7+fFpzAVRiz/RnAYve7ex3YP8u0nAEsT1i2CviC+/wCYH7COVBgnPv6deCKmPVfAN5Mc6yPu9+Vt7/+5/fEh+UUBq+Lgctw7lYKge/GrHsSmOGuexvYpSyuiBwKzAQWZtpWVf8CfJmenMZFQOQOtFJVTxCRUpyAcK+btguBm0VkdsLn+jlQDszrQ1onAI8DP8O5UH4XeFBEahP2nXTO3OPfjHPnPA7njnKC+7meAn4BPOB+rgMy7c/d59LeimZE5HzAr6pPZPsZ0zgW2KbZFc3NBIKquipm2RJ6vqf+9gngEJxg/T3gduCzwCTgI8BFAG5O9A6cO/Rq4DbgUREpctffLCI393KcxOIecfcPzv+CV0QOd3MHl+MEn23u+jk45yCit/NxBM6NzJ1uUdMCETmul3QNSRYUBt7DItLkPh7uZbu/quoqVe3Eues6MLJCVe9Q1VZV9QM/Bg4QkZFZHv8I99itOLmEu3Hu9vrDGTjFS39V1aCqvgM8iFOEEvGIqr6mqmFV7erDvj8LPKGqT7jvfRYnmJ0Ws026c3Ye8B9VnaeqAeB6nLvJTHr7DvZX1XtTvUlEynECzTf68PlS7WciTnHQt7N8SxnOXXqsZpwAnAs3qmqLqi4HlgHPqOpaVW3GuVhHiiWvAG5T1bdUNaSqdwJ+nIswqvoVVf1KmmO8AYwXkYtEpEBELsXJkYxw17fi/Mbmufv8EU7OIPL9luGcg4hmoCxNvcJEnNzCi8BY4NfAIyJS05eTsqezoDDwPqmqle7jk71sty3meQfOjxsR8YrIL0XkAxFpwcnuAmT7w33TPXY5zg9/Ds4FrD9MAQ6PCXpNOHfnY2O22bgb+z4/Yd9H49z5R6Q8Z8D42OOqagdOMVIm6faXyY+Bu1V1fZbbJ3FzQM8AN6vqfVm+rQ2oSFhWgXPhzIXtMc87U7yOnK8pwHcSvrtJON9Lr9wc0tk4gXE7TnHfc8Amd5Mv4OTm5uDk5j4LPCYikX0nnpMKoC0maMTqxLmp+Yuqdqvq/Ti/m6MypXMosaCw57kY55/kJJxikKnu8rQtKtJR1e04d1lnuova6bkDi1QE16Z4azobgZdjgl6lWyQT28JpV4fl3YhzoY3dd6mqpqqsTbQV5y4QABEpwSnG2N00pXMi8HUR2SYi23AugP8Qkf/K5s1uJeozwKOq+vM+HHcV4BORGTHLDmAXGwL0o43AzxO+uxHZBjtVfVlVD1XVKuASnHqr+e7qA4HH3Bxd2C0O3Ap81F2/HOccRPR2PpaS/FsYdsNIW1DY85TjZJMbcC7gu3yXL06/gk/R80+yCigWkdPd5qY/AIr6sMvHgJkicomb1S8QkUNFZN8+Js0nIsUxjwLgHuBMEfmEm1sqFpHj3SKWTP7lvvejIlKIcycfG0S3A1NFpL/+H07EKfM+0H1swSlP/yNEc3vFgA/wxHxGRKQCeBp4TVWvSdyx28SyGOeuGPe9RQDqtAp7CPiJiJSKyFE4NxB3u9tOFad57NR++pzZ+hPwZbfcX9y0ne4Ws2UkIge5v6UKnNZAG1X1aXf1AuB0Ednb3ffJOHUry9z1dwHfFpEJbu7hOzgNHlL5NzBKRC51v6PzcG4mXtuVD72nsqCw57kLpxXNZmAF8GYf33+kuO3PgfeAOuBrAG5Z8FeAP7v7b6cnm56RqrbilMleiHMh3Ab8ir4FFnBaKHXGPP6qqhtxLnDXuWneCPw/svgNu2XeXwPux7mLbAN24ARXcFpzATSIyNvZJFCcdv2fSXO8BlXdFnngtNjaqapt7iaXuJ/rFuAY9/mf3HWfAg4FLpP4/iyT3fVT3O0jgbwTp3I04itAifv57gOucj8/ODmWyG9nwKjqQuBLwE3ATmANTmsmAETkVhG5tZddfA+ox/nOx+Gco4i7cL7Xl3DqU34PXKmq77vrb8Np0vouTqB43F0WOXabiBzjprMROAunQUEzcA1wtqrW78LH3mNJ6qI1Y4YuESnDaRo5Q1XX5Ts9A0VEfgDUqeptGTc2w5YFBTMsiMiZwPM4xUa/Bg4HDk5T4WjMsGXFR2a4OBunSGsLTh+PCy0gGJPMcgrGGGOiLKdgjDEmypfvBPRVTU2NTp06Nd/JMMaYPcqiRYvqVTVjv6M9LihMnTqVhQszDtVjjDEmhohsyGY7Kz4yxhgTZUHBGGNMlAUFY4wxURYUjDHGRFlQMMYYE2VBwRhjTJQFBWOMMVF7XD8FY4wZSpZtbiYQCnPw5FFxy19fU8/oimKmVI/gobc3sbmpi0OnjuKYGX2Z96rvLCgYY0wenfGHeQCs/+Xpccsv/vNbAFx32ix+8YQzPcTXTpie86BgxUfGGDPIhMM9A5XWtfqjz2vK+jpfVd9ZUDDGmEEgdsTqps7umOU921hQMMaYISwQDEefN8cEgoa2ntxBMCbXUF1WmPM0WVAwxpg8aWjvufjXtwWiz+tigsKO1q7oc8spGGPMEFbf2hMI6ttSB4iV21qjz2stKBhjzNBVH5NTWL6lhaaOAKoaV3z0QV179HlFSe4bjFpQMMaYPGmMyRH89LEVHPiTZ7n9lbU0tgdSbi8iOU+TBQVjjMmTkFuJfNjUquiyJ5dti6tcBjj7wPG8+r2PDUiaLCgYY0yeKM7F/+ApPb2Zu0PhuGaoAJUlBUyqGjEgabKgYIwxeRK5+HtiSoUCwXA0WEQMRLFRhAUFY4zJk8il3xNz0e8OhUmICQMqZ0FBRCaJyIsiskJElovIN1Jsc7yINIvIYvdxfa7SY4wxg00kpyAJOYVEA5hRyOmAeEHgO6r6toiUA4tE5FlVXZGw3auqekYO02GMMYNSpJgotngoEArnM6OQu5yCqm5V1bfd563Ae8CEXB3PGGP2NNGcQswyfzAcNw6Ss36I1SmIyFTgIOCtFKuPFJElIvKkiMxJ8/4rRGShiCysq6vLYUqNMWbgJdYpJLY+Gsjio5wHBREpAx4EvqmqLQmr3wamqOoBwB+Ah1PtQ1VvV9W5qjq3tja3Y4kbY8xA6alo7lnmtD6KN4AxIbdBQUQKcALC31X1ocT1qtqiqm3u8yeAAhGpyWWajDFm0HCzBJ6YqBBWhmZOQZyak78A76nqb9JsM9bdDhE5zE1PQ67SZIwxg0nk2p940c9nP4Vctj46CrgEeFdEFrvLrgMmA6jqrcB5wFUiEgQ6gQs1sYbFGGOGqJ7Oa5JyecRAFh/lLCio6jwyfBZVvQm4KVdpMMaYwSxyD+zJdNUfCsVHxhhjepeqRzMw9JukGmOMSZausDyp9ZHlFIwxZuhLn1OI327INEk1xhiTXtZ1CgPIgoIxxuSZJyEqJDdJHcC0DNyhjDHGxOoZJTVT8ZFVNBtjzJAXyREkFh9ZRbMxxgxD6TuvJTZJHTgWFIwxJk9SDYgHEAjmb/AjCwrGGJMn6esULKdgjDHDTk+dQvxlP5wYFKxOwRhjhr6eOoX45WFrfWSMMcNXYk7AcgrGGDOMJeYEbJgLY4wZhiIVypZTMMYYk/UkOwPJgoIxxuRJulFSw6pxlc8DOR2nBQVjjMmT3lofJQaKgWJBwRhj8iTSTyFV57XYoGB1CsYYMwykzyloXCCwfgrGGDMMROoUEnMKicVHllMwxpjhINIkNWFxUkXzwKXIgoIxxuSL4uQCUvVTsJyCMcYMM6pOLiApKISJyx5YnYIxxgwDiqbsg2A5BWOMGYaiOYUUYx/lqZuCBQVjjMmXSJ1CYulQYk5hIOUsKIjIJBF5UURWiMhyEflGim1ERH4vImtEZKmIHJyr9BhjzGDj5BSSawwU8jbMhS+H+w4C31HVt0WkHFgkIs+q6oqYbU4FZriPw4Fb3L/GGDPkKU75UXI/hfi6hiHRJFVVt6rq2+7zVuA9YELCZmcDd6njTaBSRMblKk3GGDOoROsU4jmd13peD7mKZhGZChwEvJWwagKwMeb1JpIDByJyhYgsFJGFdXV1uUqmMcYMqHT9FJLGPhrANOU8KIhIGfAg8E1VbdmVfajq7ao6V1Xn1tbW9m8CjTEmzxJrFZKbpA6RfgoiUoATEP6uqg+l2GQzMCnm9UR3mTHGDHmq6lQ0p+i8JkOt+Eic0PYX4D1V/U2azR4FPue2QjoCaFbVrblKkzHGDCaR/gipxj6KHyV14OSy9dFRwCXAuyKy2F12HTAZQFVvBZ4ATgPWAB3AZTlMjzHGDCqKe8FPqlNImGRnKDRJVdV5ZAhw6sxa/dVcpcEYYwYzJ6eQxTAXA5gm69FsjDF5omjKYS7CqnFLhkSdgjHGmN6pW36U3CTVxj4yxphhKVXnNWeYi9jioyHSJNUYY0x66g5nkWqYCxs62xhjhpneZl7LV5NUCwrGGJMnmm7sozCWUzDGmOEmMvNayrGPYq7OVqdgjDHDQCSnkJhXCCd1Xhu4NFlQMMaYPOm1TiHmtdUpGGPMMKAKqS754YSezkNmlFRjjDG90ZQD4jnzKfS8tpyCMcYMA9HWR9ZPwRhjTPqhs4fgfArGGGOyk7qiOT+DH1lQMMaYPHFGSZWkAKDRiRYc1k/BGGOGgWjxUaYmqVZ8ZIwxQ19ChiAqceyjgWRBwRhj8iQy81pyTiG+yMj6KRhjzDCgKJBcZ6A2SqoxxgxDaesUrEmqMcYMO5GxjxIlNkm11kfGGDMMqHvxzzRHs+UUjDFmGIiOkpohJ2B1CsYYMwRsbe5k6jWPs2B9Y8r1PWMfJa8TG/vIGGOGljc+aADg3rc+TLneySnka0CL1CwoGGNMnqjbczllTqGXV7lkQcEYY3LEmUSnl/XgXu+TL/pW0WyMMcNNb3UKaZ7nWs6CgojcISI7RGRZmvXHi0iziCx2H9fnKi3GGDMYKZq2TiFf03H6crjvvwE3AXf1ss2rqnpGDtNgjDF5l+6Snm7mtcT3DImcgqq+AqRuh2WMMSbtzGuwB9QpiMjRInKZ+7xWRPbqh+MfKSJLRORJEZnTy7GvEJGFIrKwrq6uHw5rjDGD3SDupyAiPwL+C7jWXVQA3LObx34bmKKqBwB/AB5Ot6Gq3q6qc1V1bm1t7W4e1hhjBla6RkjRmddSdl6LeT4Im6R+CjgLaAdQ1S1A+e4cWFVbVLXNff4EUCAiNbuzT2OM2ZP0FB/1XqcwkJUK2QaFgKoqkWa1IqW7e2ARGStu7YqIHOampWF392uMMYNN2ormyPqMOYWBk23ro3+IyG1ApYh8Cbgc+FNvbxCR+4DjgRoR2QT8CKfYCVW9FTgPuEpEgkAncKEbeIwxZliIzLyWSr5mXssqKKjq/4rIyUALsA9wvao+m+E9F2VYfxNOk1VjjBmm0g9zkS8Zg4KIeIHnVPVjQK+BwBhjTPaidQqp+ikM1uk4VTUEhEVk5ACkxxhjho2e+RSS5aufQrZ1Cm3AuyLyLG4LJABV/XpOUmWMMUNApkrSdDOvQUKdwgDmFbINCg+5D2OMMf2k15nXBnNOQVXvFJFCYKa7aKWqducuWcYYM/T1OvNamue5llVQEJHjgTuB9TjpmyQil7rjGxljjNkFbsevlOskTzXN2RYf/Rr4uKquBBCRmcB9wCG5Spgxxgx10ZnXUqyLzykMvmEuCiIBAUBVV+F2RDPGGJNBL9d0SRMVBvsoqQtF5M/uxDjHi8ifgIW5TJgxxgwlH9S1JS2L1ilkGPtoUPVTcF0FrAC+7j5WuMuMMcZk8NLKOk789cs8snhz3PLozGspcwr5GeYi26DgA36nqueo6jnA7wFv7pJljDFDR2N7AIDlW1rilvfkFAaPbIPC80BJzOsS4Ln+T44xxgwfvQ5zEft8ENYpFEfmPgBwn4/ITZKMMWZoyHbg55TX/ME69pGrXUQOjrwQkbk4w10bY4zZRb3OvJan6Tiz7afwTeCfIrLFfT0OuCA3STLGmOFBFUg381qepl7rNacgIoeKyFhVXQDMAh4AuoGngHUDkD5jjBmy3JiQ0mCtU7gNCLjPjwSuA/4I7ARuz2G6jDFm6NMsO68NWIIyFx95VbXRfX4BcLuqPgg8KCKLc5s0Y4zZs2UcOhtF8GRRpzBIio8Ar4hEAseJwAsx67KtjzDGmOEpQ1SINklNsW6w5hTuA14WkXqc1kavAojIdKA5x2kzxpg9mmaICtH5FDJNxzlYWh+p6s9F5Hmc1kbPaE+jWw/wtVwnzhhj9mThjDkFt0lqyrWDdOY1VX0zxbJVuUmOMcYMHeEMndd6cgrJ6wb7KKnGGGP6KFOH5sj6gcwJZGJBwRhjciTTMBdOTiFdj+b8sKBgjDE5knHkI3fmtVSs+MgYY4aYcIaa5l7rFPJU0WxBwRhjciRz66NehrmwnIIxxgwtWfVoltSNUgfr2Ee7TETuEJEdIrIszXoRkd+LyBoRWRo7NLcxxgwFGSuaIzOvZZqOc4gUH/0NOKWX9acCM9zHFcAtOUyLMcYMuGyapKYb5iLWkMgpqOorQGMvm5wN3KWON4FKERmXq/QYY4aXqdc8zm+ezW8/20yd1yIyDnPRXwnKQj7rFCYAG2Neb3KXJRGRK0RkoYgsrKurG5DEGWP2XJFWP79/fnV+05EppwCkKxzK18xre0RFs6rerqpzVXVubW1tvpNjjBnkQlneoedaxgHxVLMa5mLQzLyWY5uBSTGvJ7rLjDFmt4Qy3aIPkMTYlDpHMLDzJWSSz6DwKPA5txXSEUCzqm7NY3qMMUNEtmX5uZbY+igxVZGK5lTy1SQ1ZxPliMh9wPFAjYhsAn4EFACo6q3AE8BpwBqgA7gsV2kxxgwvgyWnkLlOQdMPnD1IJ9nZZap6UYb1Cnw1V8c3xgxfgyQmZB46u7ecQmw/hUE0HacxxuxxMo05NFAy9lMgy+Kj/kpQFiwoGGOGnEHT+ihjTiF98VHsYmuSaowxuyGSU8h3o56s+imkjQlDb5gLY4zJi0GTU8g0JJ6NkmqMMbkXaX2U79b/2eQU0lUi28xrxhjTTwZJRiGLAfFs5jVjjMm5wdJPIbs5mlOvix/7yOoUjDFmlw2WOoXEfgqRS/vijU3sbA9kP/NaTlKXWs46rxljTL4M1n4KkZef/ONrzBxTFp15bTCxnIIxZsiJ5BTyfcFNjE2xxUmrtrf1nlOIfW51CsYYs+sGTZ1CQpPUsMbnYlTJqvzI+ikYY8xuiNyQ57tgJrH4KKyadX2H5RSMMaafDJacQmJFs2py2gbbKKkWFIwxQ85gaX2UMqcQV3ykWTVJHcioYEHBGDPkDJbWR4k5hcTioyyrFKxOwRhjdkdokAyIlxiaUlU0D7aZ1ywoGGOGnMFTfJRYp5BQfDQIZ16zoGCMGXJ6Wh/luZ9COPl1KNucgs28Zowx/WOwtD5K7KegpKhTyOJ6bzkFY4zZDYOl+CgxNoU1OaeQ/94U8SwoGGOGnMHS+ihVk9T4IqVemqTa0NnGGNM/onfj+W59lKLzWjAmKvQ+9pENc2GMMXHq2/x8+4HFdAZCfXpfYv+AXNjZHuBbDyym3R/MOh1h1bhlvc6nENcmdTcS2kcWFIwxg9avnnyfh97ZzKNLNvfpfQORUfjd86v59zubuX/BxrTbpOqnEIopPnJmXss8HacVHxljDD0Xd08fr4oD2fqot5QlVzQn9lPILqdgrY+MMYaeMvm+ttMPR9/X70napXREJHVey7ZOwfopGGNMT/GLp4/XxMHSTyGx/Cgcjm8u6wyIN4x6NIvIKSKyUkTWiMg1KdZ/XkTqRGSx+/hiLtNjjNmz7Ood/2AJCikHxEsoPsrGkKhTEBEv8EfgVGA2cJGIzE6x6QOqeqD7+HOu0mOM2fPsap3CQLQ+ykZyP4WEtGU7zIUC910E79zT/4lM4Mvhvg8D1qjqWgARuR84G1ixOztdW9fOBbe9EbfsjP3HccmRU+kMhPj8X+cnvee8QyZy/txJNLYHuOqeRUnrP3vEFM48YDxbmjr51gOLk9Z/6Zi9OWn2GD6oa+O6h95NWv+1E2Zw9Iwalm9p5if/Sf543ztlHw6ZUsWiDY3c+NTKpPXXnzmbOeNHMm91PX94YXXS+l+csx/Tast4bsV2/vTq2qT1v73gQMZXlvCfJVu4580NSetv+ewhVJUW8s+FG/nXok1J6/922WGUFHq5+431PLZ0a9L6B648EoDbX/mA59/bEbeuuMDLnZcfBsDvn1/Na2vq49aPGlHIrZccAsCvnnqftzfsjFs/bmQx/3fhQQDc8J/lrNjSErd+79pS/vuc/QG49qGlrK1rj1s/e3wFPzpzDgDfvP8dtjZ3xa0/eMoo/uuUWQB8+e5F7OwIxK0/anoNXz9xBgCX3jGfru74po8n7juaK46dBpD0uwP77eXytxcIhqlr8wPwwvs7uPetD+PW9/bb29HqvC9SLp+L315LV3f0eexvr7mzm7JiH4dOrUoKTgs3NLL5kY64ZYJw6R3Jv503Puj5PJfe9iKy9WDYPALmO7/D3f3tpZPL4qMJQGxbrU3uskTnishSEfmXiExKtSMRuUJEForIwu7u7lSbGGOGmHc2NrFpZyfQ9+KTxE5jAyUQDPP+tlY+2NEGJLc+QokrM8o6le07QDxQWtsPqeyd5Orkich5wCmq+kX39SXA4ap6dcw21UCbqvpF5ErgAlU9obf9zp07VxcuXJiTNBtjBo+p1zweff7Hiw/m9P3HZf3eu95Yz/WPLGdEoZcVPzklB6mDHz+6nL+9vp7rz5jN5UfvBcDq7a2c/NtXmD66jOe+fRxfvHMBz8Xkro/fp5bLj9qLz7k5g9JCLxceNpkfnjE77vMC/OjM2dzwnxX4CLK66tvIlI/CBXfvcnpFZJGqzs20XS5zCpuB2Dv/ie6yKFVtUFW/+/LPwCE5TI8xZg+VONpoJvmqaI7kaCIZm5QD4mU785r79zjPEqSjHg68uB9Tml4ug8ICYIaI7CUihcCFwKOxG4hIbOg/C3gvh+kxxuyh+nqRz1dQiFzvNfo6RT+FUN/mUzjX+yo6ogamn9TfyU0pZxXNqhoUkauBpwEvcIeqLheRnwALVfVR4OsichYQBBqBz+cqPcaYPVdfL/L5an2UOGR3yh7NcTmF3vspjKSNEz1vE97vS3i9Bf2e3lRy2foIVX0CeCJh2fUxz68Frs1lGowxe75gn4NCjhKS8lg9Bwu6uQBJsQ6czmtJczSn2W9F+4csKb7C2e9+F/ZbejOxHs3GmF0WDIXjikhUlWDMiG/doXCqt/VZNjmFYCgcveBGto9ccEPh+E5jobBmnHMh8T3ZpC3gft5070rOKZA2Kkzb8ggAT4YORcbtnzEd/cWCgjFmlwRDYaZ//0l++eT70WW/fmYV07//JP5giGWbm5nx/Sd5eVXd7h8ri4vz9O8/yRfvclomJl7wj/7VCxz+i+ejr6dd9wTnp+h3EuvYG1/k0J8/16e0dQfjg2Dy2EcJAU7TzZWg7LX1CV4O7c9V3d+ysY+MMYOf370A3vHauuiyO99YD0BnIMSC9Y0AvPj+jsS39lkoyxzHC+6xEsv2tzZ3Ud/mj1u2KKEzW6LNTZ00tgd63QZ6ioygJ0BELuGpZl6LH+Yi9cxrB8tqyjq38Gjoo87+hsIwF8aYoS3gBoVUd/Hdof4t1O/r7iI5hVxWLURyAbEzqSUWH2Uc+yhNncKZ3jcIeQp5Oux0K7CcgjFm0IvkFFI19An0U11CRCjct/1Fcgq5bJoaCXy9Fx+R9Lq3mdcqaeUC74uc4X2DzaOPo40R/Z7uTHLa+sgYM3QFgiku1NrLut2QqU4hGEp9MU4VsPqv8jucdOykHFKKl8G4nEL8zGvf8f2TS3xOPcbLEz8J6/slqX1iOQVjzC7xB9PPm+wPhvq1WWgoQ/mRPyYIdQZCPa2QUkSFjj7O95xOMEVOIRjOVNEc3+opNqdQQhdne1+CGKFaAAAf+ElEQVTj0dCRHNR1K1tHH9sv6ewrCwrGmF3i7yU3EAiGoyPO9sf4aplyCrE5k/o2f7TYKPGi3B0K09nHoJAu19PtHiO2ojlx2+Q5mtPXKVzsfYEK6eTu4MnspCJvs8ZZUDDG7JJMQaHdHwR6Lp7gBIhrHlwabZmUrXX17Xz13reThjZ/a20D1z60NC4tX7prIX+et849Hnz7Hz1DkncEQrQHgn06dkea7aPFR+Ew/1q0iZtfWpNUfJSq81pSpkcE3rmHHxbcwwfhcSzQfZzFAzrfWg8LCsaYXdJ78VE4WkwTe2fe1R3m/gUbufhPb8Ztv2lnB1OveZynl29Lub9Hl2zh8aVb44LJkf/9PBfc/ib3zd9Im79nSP33t7XGvfeht3vG4ewMhPqcU0hX3BStaA4p3/3nEm58amWK4iMSXmtSpbkALLqTbvXy5e5vEc07WE7BGLMn6a0yORDsKaaJvdNOd9f97qZmAB5MMRFPrJICb/R57IRKOzucoDBxVEmv7+8IBLOqU4gt90+3faQYKLZoK+mcpOy8Fr9JZdcm2DSfXwfPZ7VOjC7PU0ywoGCM2TW9FR/5g+FoMU3sRTXdBTbbWod0gajJDQqjRhT2+v5si49im9SmC2SRVkxxTVKTio9IeK1JRUqz6p4C4JHQUXHLB7JvQiwLCsaYXZIqKGh0XSgmp5A5KEREroPp+he0p3l/ZJrVyhG9jyTakWXxUexny5hTiAkgyU1je++8Bsqsuidh6jFspTpuW8spGGP2KLF37YkX8UBMTiFS4Qy9VdpGhodwLoXp+hJE3p/YoqnJDQqZcgrtgWBcetIFn9j6knRpTtUktcOtCI/2qE7sp6Dx2+8vaxnV+SHsd37S/q31kTFmj9LbhTMQ0/SzsztzTiHx7j19UAhF9x9rZ7T4qPecQmcgFJeedMVRgSxyCt0pOq81d3bHrUuVU4itr/iUdx4hKYDZZyftP19BwXo0GzNIdXWHeGbFdk6YNZpXV9Vx6n7JcxS/tbaBsSOLmVJdCsDLq+rYd2w5oyuKAXhq2TaOnFbNyJL4i+WmnR182NjBR6fVZJWWBesbqS0rYmpNaXRZ4oVzQ0MHbe5duJNTcC6m7f7koNAdUpZuaooO+xDJVUQuhOnGToq8v8Mff6He6Q5cN6o0Q07BH4xLz6ur6ygr8iEiHDmtp/gmtvjo/vkbOWP/8Un7SlXRfN/8D530B5XHlm6JptdLiI97FrJXdzf7bSvnpoKXmCR1zJRNrKs+hukllUn7z1eTVAsKxgxS//P0Sv4ybx3jRxazpbmLx79+NHPGj4zb5oLbnaad6395OsFQmEvvmM/U6hG89P8+xsbGDr58zyJOnj2GP30ufr72U//vVVr9Qc49eCI3nD2HsqLeLwXn3+oMM33V8dNYvb2NX59/QNyFs7WrmzP+MC/62h8M09YVjK5TdWYYi81RnHXTa5QX+2jtCnLmAc5FtycopL6D74wUSSXkTLKtaG7tCsY1X73i7kXR5+t/eXr0eWzAm7emnsb2AFUJAScSuGL7TkQyBttaurj63ncooYtv+f7DHFnPSd53IACsgxbPCN4Oz+B5PYjy/b7K9BRptZyCMSbOh40dAGxxm142tMUP45xYHt7kFl2sb3DeF7lQflDXlrTvVveO/sG3N7HvuHK+eMzeadMRW9xxy0sfALB4UxP+7thexPFp83eHaWj345FIS6QQZUW+pKKYSLHRM27/hEDQOVYkKIwbWRzX9LQ9ReU1pK5o/uknP8IPH14Wt11Du5/61gCgFBNAERShGD+B5u0Uej2AEmptZras56K9Oli3YQOhV5ZBZRl4CqCgGIoqOK5rCd8qeBkaKjnSO4oqacFLmI941lOvIwkjTJI6Zns20KbF/Cl4Go+VnsPH9qnllvk78VPIjNFlPHvccWnPfT5YUDBmD5HYmzdxrP/E1/Xt8fMHpJNpRNNIOXmshjY/gVBPehLnKqhr66I7pOw7roL3trbQ0OZPGRQ8HoGwRnMdnd1uL2j3Lvx7p+zDDx9eHi2W6owWSaXOKVTG5BQqOjfxUc8yiuhmotQxQzZzwIoQ3kAz3yhax3hJ6FX9256nHwGeKAK2AAXAW8nn5RqgwVNOQXeYjxe006SlKEKdjqRcOujGS4ACvt99OX8PnQTAeIpp8tXipx2AmrKi5B3nmQUFY/YQiRfnxAtxYk6ivjW7oBDMMNhc4nEiy2JzChvc3EnElibn7n7W2HLe29pCfZufKdWldCRczBMrenvqHJzlBV5P3DaRYJAqp1BKJ5PrXuZi7+tMkDrOfOUJzi7sOV6TltLVXkkzZSwOT+ee8NRoqX0XhVx+3CwmVDp1MWvq2vnja9s4+eRTuPbp7fz8vIM5Y04thIPQ3Qn+Fq68Yx4vN9fiKywmGOiii9QXeJ9HiDTWTRw6O7FIKla++ilYUDBmkEqcUjIpJxBzsQ6FNVqE0rM+86xhqfabqC5lUAgQCIUpL/bR7g/y3taWuPVbmjoBJygA1LU6x+jo7r2PQKQCuTsUpoAgNU3vcjkPU+7rYIrsYMp6gbuKmN3SyiOFOymng7Gyk85AEeVF7RQ+G+IXBRBWYUf1EXx980n4KaCJMlqKJzJ5VBn1rX46wsFoi6WIoycfyoRZowFYv2I7/351IedMnEMz7Wzr9EJCZfC7bKOLLggopAkIAGMqitnsno/EfgqjStO3lspXPwULCsYMUk0JOYPEi3dszqCpI0BDzPpwWGlwL+apOmsV+nruwLe3dCWtj5UquNS3+inwehhR6KXI52FlwnhDkYvgnBoP+8laZFMQSqsYX7+aT3tXUEMzldJOtbRQ7WlHwkHGyE5KW4Lwh1KmBcMsKNpO5QvtHFEA3eplk9bg6S6HQBVBfDRoBZuo4cXwQRQToIlSLrvkMk786yaaKOWnRx7O/H8uiaZp1sgS6lv9NLT7mT66LCkoxAbZSJFaTVkRBV6JO7cR3RlGbo0YU1EUExTi64KqeqkYt4rmARRpX13k86Zc3xkIUeAVfN7eu3GEwoo/GGJEYf+dxkAwTFiV4oLUacunbNIWDivrGtpRhbEji9nZHiAYVsaNdLLlxQVe2vxBSgu9qML6hnZKCr2MG+mMWdMRCFLk89LS2U0wrNSUFdLqDxIIhvF5hIriAtoDQUYU+ujsDlHs8+APhinwegirM99tOAwe96vzB8MIUF7cc0cWDIXZuLOTKVUjaAsEKfJ5UHW2rSj20eYPxm3f7g9SXOClIxCk0OchFFYa2gKEwsqUamdmrA8bOxhT4VSKThxVQoH722nu7Kau1c+4kcWUFvnY2e5cvCeOKmFbc1faIaHLi33RZpYRHzZ20NUdoq7Vz6SqEXEXsQ2NHdEgALBkU1O0wrmhLYCq0hEI0dTZTWVJAYUxxTI73GKmpo5AXAAo8nmYVDWC9xNyATPHlLGuoZ1Jo0ZQ4Q0yu3AjdfWNTPIEGCeN7C9rqQi1M66wgQMe/JD/FAXhTeBNuAScMnqgSwtooAJ/QSUtAdikNfhDJVRXj6a1q5t5jROYc+w5XPJ8IU2Ug7eA2RUV3HHhodz/1of8etOquHT5PMJVMz7GVp4AwJNwUR01ojA6WN74kSUs2xz/uVbvaGPNjrbo9wbO77W6tIj19e3RdRHZTiQ01v3tg5MDaooJRpW9BQVrkjpwjrvxJdr9Qd694RMp1+97/VN8Ys4Ybrtkbsr1Edc+tJR/LNzEuv8+rd/K/076zctsa+li1c9O7Zf97a5FG3YyqaqE9fUdfOXvb1Pf5mf9L0+ntaubpZuaOWp6Tzv3YCjMZX9bwKur69Pu7z9XH82ZN83jM4dPRoF733LadX/+o1P5yISRfPefSzjnoAk89I4zsuUPTt+Xnz3+HgDFBR6OnVHLMyu2c+Ks0Tz//g6OnVnLK6vqok0bT99vHI+/uzXpuN88aQYXHjqZZ9/bzpsfNPD4u1v59skz+c2z8ReWU+aM5cWVO/jGSTMoLfQRCis3vbiGypIC1ta3J+33sqOmsq6+nZdW1kWXfebwyZx1wHg+bOzgf55eyY5WPzPHlHHWAeP5wwtreh0zKEIkuTfsk8u28eQyZ5yc8w+ZyIbGnnL8c25+PW7bT938Gj5CTJU6SsNd3Pfvh1m4ro6N9a14JcxBBBnlaaNamhm7rZ13/nIvSzbUo+EwXsL4COEhTPUIH9M7u7ipIEg5HVRIB1Na6gmGIbDdx2hpppBuiLm21WsFO7WcHVShR1zN/3urkB2dQjc+AuqjgQq2aA0BNzpcecTe3Pby2p4dLO15+tA+H6XueeezTaksYcmmZg752XMpz1l5sc+puMYpthpRGH/zss/Yct5Y2wDAzDHlPLNie9z6219Zy+2vrI1bVlrkZVxlsXvuU4/gmsnkqp6+Hc2d3TwVMxJspHgt1oTKEjY3dVJc4GFSVQkbGzt36bi7algGhW29ZJcjFVxPL9+edpuIfyx0RnRs6QomdQ7aVR82dmTeaICoKufe8jpjK4qTztl3/rGEZ1ZsZ8H3T6K23ClPXbhhJ6+urufK4/Zm9fY2Xnh/R9I+/+855yL8dzcYjBpRwJHTqvnb6+uj20QCAsAz7vcwfXQZda3+6D/y8+6+X1nlXIxb3TbxqQKCc9zV1LX6o8cFJ+AlivzD3vjUyrjliUU35x8ykYcXb+avr60n0fqG9mj/gYhV29v432dWMaGyhDEVRbz9YRMFXuHXnz6wZyMN4wkHEe3m+bdXsXLtOqqlhVK6KCCEjyAlvjDTR/nYsbiRiZ5ufjSrlNbG7TTvbKCIbiYXtjKZbXhDXQgxwWcpXAwpi75DePB/WMBMj4eCogJUvKh48YeFVr/iK/RRWjKCD1qgtqaWTb7ZLNvSSpEEKayo5ciPncn7zV5GlpdTUFbDz17rYNWONm695BA8k0dx2Uea+aCuJ6DOHFNGV3eYQDBMKKzsP3EkB0ys5L2tLfzhhTXMnTKKjTs7uO60fTlwYk85/q/O3Z8drX7umLeOQDDMD8+YTUmhl+ICD6u2t7GX24HvuW8fS215MSUFXm675BCmVpcSCIaZXD2Ct9Y1UlHs4+oTpjN36iiqSgvpDimFXg/rGpw0dgaC/PeT7/PpuZMYXV7Mbz59IO9ubk46b4Jbkb6tlcqSAqrLCikp8BJWWL29lemjy+gOKRNGlbDfhJHMHFPG+9taUWB6bRn+YIiDJo+K7u+1a07AK0J7IMgHO9o4dmYtj119TMo6nVwalkGhN5kq3VKpb/P3W1CIiHT2yacW90KbGBDCYWWZ+09S3+aPBoVtbnvyT8+dxFPLtkWDQqTzFRD9x4sYN7KEmz9zCIs27OTcW+LvdgE2NLZTVVrIM988lsvvXBB3R55KTVlRXLHKhMoSrjp+Gj94eFk0zRHvb3OKD266+CCqRhRy8Z+ddod//fyhHDDJvRiFQ5SFmgm2bufHD8yjvrGRwycUceXUbezz3pu0+MMcUB2kWncSaN5GLU34NnupKxxBk5bRjY+qgm5CwQA+Qhw0qoz6nU00F/op9QSZ8EQnBP0Q7gbtuYifDunrLpuJFsGweQSUVKFjywn7ipHSvfFUfwKKysBXBOXjCBRWcuXfFxPCw1kHTWLl9k7e2dzKaYfN4fKPH0qwsIKugFJR7IsrMi0G6Oymotjp8fuRUBif18N4Vb73u1d5f1srp40fy5lzD+HomOTdOUsRiN61zxk/MqnTXaLT9hvHafuN4xsnzsDn9RB0jxVrWm0ZR+xdzRluz25PTPnQrLEV0efTR/fcfX9izti4fTz2taPxiNOy5/h9Rset229iTxrPPXhi9Ph71ZSyV0xP7kQzxiTf7U8fXRb3+vT9x6XdNmJCZc+w39NqnfePHOFhZIahO/rbsAsKsS06urpDSeXjqZrfZdLQFmBa7W4nLW6Qr0hnn3yqa02do2rp6o6Ohrm9pYt9xzn/kDvc7UeXF1Eb0/66trwoGhTW1sUHhRo3oEyrTf1Pt73Fz6yx5Xg8wujyzG26E7+/mrJCxrhDPry72SnqqKKFKmmltLWLWR4/s+u2URHayTW+d6iVJg6d56GsuxHadkBHPWiYQuBGcIpJ6oDH4YsABdDZXk57QRWrtZRl7AVBGEk7NdJMIUF8BeXUB50ydG9pFa3+Cta2t1NQUMqEA/d1Lt7eAvD4nIe3AIoqoLSGB9/v4vb59Ry69xh+du6BbuepEigsBW9RtPJEgHQ1PYXAi2HnAnryxDls7W5k4aatnDBqOpRWUwQUpbnuxN7sRC6SIsKYimLe39aasp29N7Ewvw8ix0hVn1da5HxCz27sP9u0ZapPHMqGXVCIbbbX0B6Ii86QfTO++Pf0T/YucmcOTuuOfAeF7S2pP1fs590R0xZ+e4ufkgIvZUU+asp7Cpl7+0esdttp95bTqi5zthldXgwo5XQyUtoYSQejpJUqWikRP4V0U4KfKmmjmmYqpIPxzQGmP+tnQdE2KuigSJI7YvGq8+fz3gLqGUlRcDJUToYJh0DZaCgbA6W13Dy/kSdXtXPeETO59GP7ce7da1iycSfXnrE/3aEwv3zy/ZTp//rR0/n9C2sAWP/Z03nrrQ18/9/L2LemghNPPSbt5wYItW1k5VtLqdJqqErf6zhb1WVF0bL2EbvRmKHC/b4GsvNVcZqGIaZ/5fSqIyKnAL/DuYn5s6r+MmF9EXAXcAjQAFygqutzmab6tgC17GSUtFHf0pUcFGIuct2hcLQVSaLYu/r+Cgqx+6lv88cNPpYPO9LkFCJtzgF2xBQt7Wj1M7qiCBHJeLEQwlTSxrhAENa1Iu11fM77EtXSSjF+pwxdwvi0mzlNQfhzF1c2bObqojqKU13YY/jVRyMVbg/TCqR6Gs/WjaeFUlp1BI2U06gVtFJClxZy19dOoXTUOGbdMA8Q1l5xWnLTFWDtiiW8q5s4f/Q+UDGeoK4liI/R5UW9Vh7vE1O0AT0X0mwmtK+tcLbt67zCiSIV1zVlRdHWculaPmW1P/dvJGAPhN3JIZjs5SwoiIgX+CNwMrAJWCAij6rqipjNvgDsVNXpInIh8CvgglylCaC+tYu7Cn/Fvp4P6bz/dzBhP6ieBiOqoKSKkev8/Nj3IjXSTPDfj1FQVglF5c6joAR8xeAtoku9nOVZxFTZxt7vvQrhcU7W3us+Is89PvAW9jwXD3i8IN6ev+IBj4eOLW0cKGuolDZY0w6hGmcd4vxNeoj7iFmWctsU26XcNmY7DdNSv41qmvHgtkiRMKV0EthUxITOVdRKkMJtbbBxJ2iYqvp3OaEwCO82MKVuI9f6FjBGdrL3znY8hc2M8nZRGO6kiACldOEVhQ9wHsBP3E5HfgroxouKj4B60GA1FEyiseoQnmoNU68jnc5IWkqDlrOTcjq0mAA+uiiknWIil62Dx1bywEVHct33nwScZotOU9eeuofScbPc+hvnPZkuPpEbhZB7UR9dXpTUpyDWPmPjy5dr+nAhHVPuFH21de1eUPCIEFKniW8kp9DXuYpTsbv3oSeXOYXDgDWquhZARO4HzgZig8LZwI/d5/8CbhIR0Wxuofpo6UsPUvHKj5ioIaZ4tnB/8Hiqu7rZ+4OVjF/9MiU4d7wnAUGvhw91NG3LV6PayQiSm4SVAL+P/G9/6D52037Aw5Eb7HnuI48uBS4tTrHiRTjOg1MRusp9ADdE1j8II4FLvQXUMYouqWGDjqJtRCVrm6GLItoppl5Hss+0vbn4YwdDaS0H/2YxTZQRxkOhz8O+Y8tZsqmZ731sH75y/HSWv7uV//7g7YzpHlHojQ6DUFZcEJfb27u2lFXb2xhfWUx9m9+Ng9ndgUaK8wrd/UVel8aM6TOmoiip2G1CpdOXodzdPnKnXpFF44TInfjulNODU0y3o9VPdWlRdCTR3fkni5TvF/iGb9n7UJXLoDAB2BjzehNweLptVDUoIs1ANRDX0F1ErgCuAJg8efIuJaawdCSNI/YCYFvRYaye9E1eae/J8vvCAUrDLZSGWqisHss6f0V0cC7RMEXhDgrVj0+78WmAAu2myCt4Ru/D+vp2vITwaBCvBvFpEC/O8+iDIF4NIYTxaBgPYcT96zwP4UEpKS4iUDiKne1+d/zGMB5VcJ8Likedv6B4UMR9LYQRjYz72PPaQ9h9v7rH7NlXz/bh6HpBnT2LUFlaQnNXiFFlxXSFPfgppq5T8Xi81JYXs7nFH0kFKsKJ+47nIzOnQ/kY7prfwNEzRlNVWsjbb6znnIMncO/za5gxuoywQnEgyKnHTQO3XuHmK0azcH0ja+vaOXSvKkaWFPDUsm2c4rYgOXn2GK48bm8+/9Gp/PW19Vx+1F78Zd5avnD03vz1tXUoTue3Lx2zN/9atIlQWPnckVMBuOGsOSzZ1MS3TprJXW+s53NHTuW3z67i4Ck9TQJv/ezBvQaIb500k0KfhzMOcFqS/PrTB3L//A+ZPa6C8Fjly8dN4zOHT+amF9YwqaqEI/auZuX2VkoKvVx76qxoa5d9xpTztROmc+FhmX/Lo8uL+O7HZ3JairkU+uLeLx3O08u3U1Hi45Ijp1DX5ufyo/fa5f197xOzKC8uiH43uXTvlw6PtmwzuSc5uCl3dixyHnCKqn7RfX0JcLiqXh2zzTJ3m03u6w/cbdL2fpo7d64uXLgwJ2k2xpihSkQWqWrvPXLJ7XScm4FJMa8nustSbiMiPpxSh4YcpskYY0wvchkUFgAzRGQvESkELgQeTdjmUZyia4DzgBdyUZ9gjDEmOzmrU3DrCK4GnsZpknqHqi4XkZ8AC1X1UeAvwN0isgZoxAkcxhhj8iSn/RRU9QlwhyzsWXZ9zPMu4PxcpsEYY0z2rD2ZMcaYKAsKxhhjoiwoGGOMibKgYIwxJipnnddyRUTqgA27+PYaEnpLD0N2DuwcgJ0DGH7nYIqqZhzkf48LCrtDRBZm06NvKLNzYOcA7ByAnYN0rPjIGGNMlAUFY4wxUcMtKNye7wQMAnYO7ByAnQOwc5DSsKpTMMYY07vhllMwxhjTCwsKxhhjooZFUBCRU0RkpYisEZFr8p2eXBGRO0Rkhzt5UWRZlYg8KyKr3b+j3OUiIr93z8lSETk4fynvPyIySUReFJEVIrJcRL7hLh8250FEikVkvogscc/BDe7yvUTkLfezPuAOaY+IFLmv17jrp+Yz/f1JRLwi8o6IPOa+HnbnoK+GfFAQES/wR+BUYDZwkYjMzm+qcuZvwCkJy64BnlfVGcDz7mtwzscM93EFcMsApTHXgsB3VHU2cATwVff7Hk7nwQ+coKoHAAcCp4jIEcCvgN+q6nRgJ/AFd/svADvd5b91txsqvgG8F/N6OJ6DvlHVIf0AjgSejnl9LXBtvtOVw887FVgW83olMM59Pg5Y6T6/Dbgo1XZD6QE8Apw8XM8DMAJ4G2d+9HrA5y6P/l/gzHlypPvc524n+U57P3z2iTg3ACcAjwEy3M7BrjyGfE4BmABsjHm9yV02XIxR1a3u823AGPf5kD8vbhHAQcBbDLPz4BabLAZ2AM8CHwBNqhp0N4n9nNFz4K5vBqoHNsU58X/A94Cw+7qa4XcO+mw4BAXjUuc2aFi0QRaRMuBB4Juq2hK7bjicB1UNqeqBOHfLhwGz8pykASUiZwA7VHVRvtOypxkOQWEzMCnm9UR32XCxXUTGAbh/d7jLh+x5EZECnIDwd1V9yF087M4DgKo2AS/iFJVUikhktsXYzxk9B+76kUDDACe1vx0FnCUi64H7cYqQfsfwOge7ZDgEhQXADLfVQSHOPNCP5jlNA+lR4FL3+aU4ZeyR5Z9zW98cATTHFK/ssUREcOb+fk9VfxOzaticBxGpFZFK93kJTp3KezjB4Tx3s8RzEDk35wEvuLmpPZaqXquqE1V1Ks7//Auq+hmG0TnYZfmu1BiIB3AasAqnXPX7+U5PDj/nfcBWoBunvPQLOOWizwOrgeeAKndbwWmV9QHwLjA33+nvp3NwNE7R0FJgsfs4bTidB2B/4B33HCwDrneX7w3MB9YA/wSK3OXF7us17vq98/0Z+vl8HA88NpzPQV8eNsyFMcaYqOFQfGSMMSZLFhSMMcZEWVAwxhgTZUHBGGNMlAUFY4wxURYUzLAhIiERWRzz6HXEXBH5soh8rh+Ou15EanbhfZ8QkRvcEV6f3N10GJMNX+ZNjBkyOtUZ+iErqnprLhOThWNwOlsdA8zLc1rMMGE5BTPsuXfyN4rIu+48BNPd5T8Wke+6z7/uztGwVETud5dVicjD7rI3RWR/d3m1iDzjzmXwZ5wOcpFjfdY9xmIRuc0d2j0xPRe4g9l9HWdQtz8Bl4nIcOqJb/LEgoIZTkoSio8uiFnXrKr7ATfhXIgTXQMcpKr7A192l90AvOMuuw64y13+I2Ceqs4B/g1MBhCRfYELgKPcHEsI+EzigVT1AZzRXZe5aXrXPfZZu/PhjcmGFR+Z4aS34qP7Yv7+NsX6pcDfReRh4GF32dHAuQCq+oKbQ6gAjgXOcZc/LiI73e1PBA4BFjhDNFFCz8B8iWYCa93nparamsXnM2a3WVAwxqFpnkecjnOxPxP4vojstwvHEOBOVb22141EFgI1gE9EVgDj3OKkr6nqq7twXGOyZsVHxjguiPn7RuwKEfEAk1T1ReC/cIZVLgNexS3+EZHjgXp15m54BbjYXX4qMMrd1fPAeSIy2l1XJSJTEhOiqnOBx4GzgRtxBnE80AKCGQiWUzDDSYl7xx3xlKpGmqWOEpGlOPMbX5TwPi9wj4iMxLnb/72qNonIj4E73Pd10DP08g3AfSKyHHgd+BBAVVeIyA+AZ9xA0w18FdiQIq0H41Q0fwX4TYr1xuSEjZJqhj13Ipa5qlqf77QYk29WfGSMMSbKcgrGGGOiLKdgjDEmyoKCMcaYKAsKxhhjoiwoGGOMibKgYIwxJur/A9ihUnbmZvwaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores) + 1), scores)\n",
    "plt.plot(np.arange(1, len(scores_average) + 1), scores_average)\n",
    "ax.axhline(y=0.5, xmin=0.0, xmax=1.0, linestyle='--')\n",
    "plt.title(f'Final Buffer Length: {len(agent1.buffer)}, Time: {run_time:<6.1f}')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "filename = f'model_dir/tennis/maddpg_{env.session_name}'\n",
    "filename += f'-PER' if USE_PER else f'-ER'\n",
    "filename += f'_{PRELOAD_STEPS:d}'\n",
    "if USE_PSN:\n",
    "    filename += f'-PSN'\n",
    "plt.savefig(filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Test the Agents\n",
    "\n",
    "Check that the agents learned by visualizing them in the Tennis Simulator.\n",
    "\n",
    "Note: You may need to restart the IPython Kernel if it's the same kernel you used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score over 5 episodes: 2.66, 499.65 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create Environment\n",
    "env = UnityTennisEnv(file_name='Tennis_Linux/Tennis.x86_64', no_graphics=False)\n",
    "\n",
    "# Restore agents with checkpoint\n",
    "agent1 = Agent(env.state_size, env.action_size, 0, restore='model_dir/tennis/maddpg_last-best.pt')\n",
    "agent2 = Agent(env.state_size, env.action_size, 1, restore='model_dir/tennis/maddpg_last-best.pt')\n",
    "\n",
    "n_episodes = 5                  # play game for 5 episodes\n",
    "scores = []\n",
    "\n",
    "t0 = time.time()\n",
    "for ep_i in range(n_episodes):\n",
    "    score = np.zeros((2, 2))           # initialize the score (for each agent)\n",
    "    obs = env.reset(train_mode=False)  # reset the environment    \n",
    "    while True:\n",
    "        actions1 = agent1.act(obs[0], train_mode=False, perturb_mode=False)[0] # select an action for agent 1\n",
    "        actions2 = agent2.act(obs[1], train_mode=False, perturb_mode=False)[0] # select an action for agent 2\n",
    "        obs_next, rewards, dones = env.step([actions1, actions2])  # send all actions to tne environment\n",
    "        score += rewards               # update the score (for each agent)\n",
    "        obs = obs_next                 # roll over obs to next time step\n",
    "        if dones.any():\n",
    "            break\n",
    "    scores.append(np.max(score))\n",
    "\n",
    "print(f'Average score over {n_episodes} episodes: {np.mean(scores):.2f}, {time.time()-t0:.2f} seconds')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "1. Figure out how to make agents learn less \"jerky\" actions.\n",
    "2. Verify Prioritized Experience Replay algo **OR** Explore why adding PER causes agents to train longer (on average) in this environment.\n",
    "1. Add TensorBoard logging.\n",
    "2. Explore a more complicated Environment (Soccer) that is a blend of collaboration and competition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
